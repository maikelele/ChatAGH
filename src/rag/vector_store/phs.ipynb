{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pinecone import Pinecone\n",
    "from transformers import BertTokenizerFast  # !pip install transformers\n",
    "\n",
    "# load bert tokenizer from huggingface\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\n",
    "   'bert-base-uncased'\n",
    ")"
   ],
   "id": "9a2f532434609934"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "contexts = [\"1231\", \"sfafs\"]",
   "id": "ad9e9c2368d9edab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "inputs = tokenizer(\n",
    "   contexts[0], padding=True, truncation=True,\n",
    "   max_length=512\n",
    ")\n",
    "inputs.keys()"
   ],
   "id": "e6c9c2c495651329"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "input_ids = inputs[\"input_ids\"]",
   "id": "da3722bd7dd62293"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from collections import Counter\n",
    "\n",
    "# convert the input_ids list to a dictionary of key to frequency values\n",
    "sparse_vec = dict(Counter(input_ids))\n",
    "sparse_vec"
   ],
   "id": "b48e11c4730794f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# !pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# load a sentence transformer model from huggingface\n",
    "model = SentenceTransformer(\n",
    "   'multi-qa-MiniLM-L6-cos-v1'\n",
    ")\n",
    "\n",
    "emb = model.encode(contexts[0])\n",
    "emb.shape\n"
   ],
   "id": "11f2256e1c6fb5b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pinecone import Pinecone, ServerlessSpec # !pip install pinecone-client\n",
    "\n",
    "pinecone = Pinecone(\n",
    "   api_key=\"pcsk_5KSJb6_S2hK46wjboLTgkAhmFizEcpZdk1X6tTd2N66vA7v1BaMUNZYCbgSv4t4dM9Jrkz\",  # app.pinecone.io\n",
    ")\n",
    "# choose a name for your index\n",
    "index_name = \"hybrid-search-intro\"\n",
    "\n",
    "cloud = 'aws'\n",
    "region = 'us-east-1'\n",
    "\n",
    "# create the index\n",
    "pinecone.create_index(\n",
    "   name = index_name,\n",
    "   dimension = 384,  # dimensionality of dense model\n",
    "   metric = \"dotproduct\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=cloud,\n",
    "        region=region\n",
    "    )\n",
    ")\n"
   ],
   "id": "3e7e1ecb0bbde87f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_dict(input_batch):\n",
    " # store a batch of sparse embeddings\n",
    "   sparse_emb = []\n",
    "   # iterate through input batch\n",
    "   for token_ids in input_batch:\n",
    "       indices = []\n",
    "       values = []\n",
    "       # convert the input_ids list to a dictionary of key to frequency values\n",
    "       d = dict(Counter(token_ids))\n",
    "       for idx in d:\n",
    "            indices.append(idx)\n",
    "            values.append(d[idx])\n",
    "       sparse_emb.append({'indices': indices, 'values': values})\n",
    "   # return sparse_emb list\n",
    "   return sparse_emb\n",
    "\n",
    "\n",
    "def generate_sparse_vectors(context_batch):\n",
    "    # create batch of input_ids\n",
    "    inputs = tokenizer(\n",
    "           context_batch, padding=True,\n",
    "           truncation=True,\n",
    "           max_length=512\n",
    "    )['input_ids']\n",
    "    # create sparse dictionaries\n",
    "    sparse_embeds = build_dict(inputs)\n",
    "    return sparse_embeds\n"
   ],
   "id": "1a932cdd20062610"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for i in tqdm(range(0, len(contexts), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(contexts))\n",
    "    # extract batch\n",
    "    context_batch = contexts[i:i_end]\n",
    "    # create unique IDs\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "    # add context passages as metadata\n",
    "    meta = [{'context': context} for context in context_batch]\n",
    "    # create dense vectors\n",
    "    dense_embeds = model.encode(context_batch).tolist()\n",
    "    # create sparse vectors\n",
    "    sparse_embeds = generate_sparse_vectors(context_batch)\n",
    "\n",
    "    vectors = []\n",
    "    # loop through the data and create dictionaries for upserts\n",
    "    for _id, sparse, dense, metadata in zip(\n",
    "        ids, sparse_embeds, dense_embeds, meta\n",
    "    ):\n",
    "        vectors.append({\n",
    "            'id': _id,\n",
    "            'sparse_values': sparse,\n",
    "            'values': dense,\n",
    "            'metadata': metadata\n",
    "        })\n",
    "\n",
    "    # upload the documents to the new hybrid index\n",
    "    pinecone.upsert(vectors)\n",
    "\n",
    "# show index description after uploading the documents\n",
    "pinecone.describe_index_stats()\n"
   ],
   "id": "28458244e5ca9f0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "34803c8cf03a8b0c"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
